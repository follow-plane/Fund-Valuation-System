import pandas as pd
import numpy as np
import datetime
import os
import sys
from data_api import get_fund_nav_history

def ensure_dependencies():
    """
    Ensure required dependencies are in sys.path.
    This helps if the user is running the app from a different environment.
    """
    try:
        import openai
    except ImportError:
        # Try to find .venv site-packages
        possible_paths = [
            os.path.join(os.path.dirname(__file__), "..", ".venv", "Lib", "site-packages"),
            os.path.join(os.path.dirname(__file__), ".venv", "Lib", "site-packages"),
        ]
        for path in possible_paths:
            if os.path.exists(path) and path not in sys.path:
                sys.path.append(path)
                try:
                    import openai
                    return True
                except ImportError:
                    continue
    return False

# Try to load dependencies at module level
ensure_dependencies()

def analyze_fund_with_ai(fund_code, api_key, endpoint_id, fund_name=""):
    """
    Use DeepSeek AI to perform deep fund analysis.
    """
    try:
        import openai
    except ImportError as e:
        import sys
        venv_path = os.path.join(os.path.dirname(__file__), "..", ".venv")
        exists = "å­˜åœ¨" if os.path.exists(venv_path) else "ä¸å­˜åœ¨"
        return (
            f"âŒ **AI è¯Šæ–­å¯åŠ¨å¤±è´¥**\n\n"
            f"åŸå› : æ‰¾ä¸åˆ° `openai` åº“ ({str(e)})\n\n"
            f"**æ’æŸ¥ä¿¡æ¯**:\n"
            f"- å½“å‰ Python: `{sys.executable}`\n"
            f"- è™šæ‹Ÿç¯å¢ƒ ({venv_path}): **{exists}**\n\n"
            f"**è§£å†³æ–¹æ³•**:\n"
            f"1. è¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–ï¼š`pip install openai` æˆ–è¿è¡Œç›®å½•ä¸‹çš„ `run.bat`ã€‚\n"
            f"2. å¦‚æœåˆšå®‰è£…å®Œï¼Œè¯·**å½»åº•å…³é—­å¹¶é‡å¯** Streamlit å‘½ä»¤è¡Œçª—å£ã€‚"
        )
    except Exception as e:
        return f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"

    if not api_key:
        return "è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® DeepSeek API Keyã€‚"

    # Check for non-ASCII characters in API Key and Model ID to prevent encoding errors
    try:
        api_key.encode('ascii')
    except UnicodeEncodeError:
        return "API Key åŒ…å«éæ³•å­—ç¬¦ï¼ˆå¯èƒ½æ˜¯ä¸­æ–‡æˆ–å…¨è§’ç¬¦å·ï¼‰ï¼Œè¯·åˆ‡æ¢åˆ°è‹±æ–‡è¾“å…¥æ³•é‡æ–°è¾“å…¥ã€‚"
        
    try:
        endpoint_id.encode('ascii')
    except UnicodeEncodeError:
        return "æ¨¡å‹åç§° (Model Name) åŒ…å«éæ³•å­—ç¬¦ï¼Œè¯·ä½¿ç”¨çº¯è‹±æ–‡ï¼ˆå¦‚ deepseek-chatï¼‰ã€‚"

    try:
        # 1. Prepare Data for AI
        diagnosis = diagnose_fund(fund_code)
        
        # 2. Setup OpenAI Client (Compatible with DeepSeek)
        client = openai.OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com",
        )

        # 3. Construct Prompt
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŸºé‡‘åˆ†æå¸ˆã€‚è¯·é’ˆå¯¹ä»¥ä¸‹åŸºé‡‘è¿›è¡Œæ·±åº¦è¯Šæ–­å’ŒæŠ•èµ„å»ºè®®ã€‚

åŸºé‡‘åç§°ï¼š{fund_name}
åŸºé‡‘ä»£ç ï¼š{fund_code}

è¿‘ä¸€å¹´è¡¨ç°æŒ‡æ ‡ï¼š
- ç´¯è®¡æ”¶ç›Šç‡ï¼š{diagnosis['metrics']['return_1y']}
- æœ€å¤§å›æ’¤ï¼š{diagnosis['metrics']['max_drawdown']}
- å¤æ™®æ¯”ç‡ï¼š{diagnosis['metrics']['sharpe']}
- ç»¼åˆè¯„åˆ†ï¼š{diagnosis['score']} / 5.0
- ç³»ç»Ÿåˆæ­¥ç»“è®ºï¼š{diagnosis['conclusion']}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦è¿›è¡Œä¸“ä¸šåˆ†æï¼š
1. **ä¸šç»©è¡¨ç°åˆ†æ**ï¼šè¯„ä»·è¯¥åŸºé‡‘åœ¨åŒç±»äº§å“ä¸­çš„æ”¶ç›Šä¸é£é™©æ§åˆ¶èƒ½åŠ›ã€‚
2. **é£é™©è¯„ä¼°**ï¼šåˆ†æå…¶æ³¢åŠ¨æ€§å’Œæœ€å¤§å›æ’¤èƒŒåçš„æ½œåœ¨é£é™©ã€‚
3. **æŠ•èµ„å»ºè®®**ï¼šæ ¹æ®å½“å‰æ•°æ®ï¼Œç»™å‡ºå…·ä½“çš„æŒæœ‰ã€å‡ä»“æˆ–å»ºä»“å»ºè®®ï¼Œå¹¶è¯´æ˜ç†ç”±ã€‚
4. **é€‚åˆäººç¾¤**ï¼šè¯¥åŸºé‡‘é€‚åˆå“ªç§é£é™©åå¥½çš„æŠ•èµ„è€…ã€‚

è¦æ±‚ï¼šå›å¤å¿…é¡»ä¸“ä¸šã€å®¢è§‚ã€ä¸¥è°¨ï¼Œä½¿ç”¨é‡‘èæœ¯è¯­ï¼Œæ€»å­—æ•°æ§åˆ¶åœ¨700å­—å·¦å³ã€‚
"""

        # 4. Call API
        completion = client.chat.completions.create(
            model=endpoint_id,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èç†è´¢ä¸“å®¶ï¼Œæ“…é•¿åŸºé‡‘åˆ†æã€‚"},
                {"role": "user", "content": prompt},
            ],
        )

        return completion.choices[0].message.content

    except Exception as e:
        return f"AI åˆ†æå¤±è´¥: {str(e)}"

def analyze_portfolio_with_ai(holdings, api_key, endpoint_id):
    """
    Use DeepSeek AI to perform portfolio diagnosis.
    holdings: List of dicts [{'fund_code':..., 'fund_name':..., 'share':..., 'cost_price':...}, ...]
    """
    try:
        import openai
    except ImportError as e:
        import sys
        venv_path = os.path.join(os.path.dirname(__file__), "..", ".venv")
        exists = "å­˜åœ¨" if os.path.exists(venv_path) else "ä¸å­˜åœ¨"
        return (
            f"âŒ **æŠ•èµ„ç»„åˆè¯Šæ–­å¯åŠ¨å¤±è´¥**\n\n"
            f"åŸå› : æ‰¾ä¸åˆ° `openai` åº“ ({str(e)})\n\n"
            f"**æ’æŸ¥ä¿¡æ¯**:\n"
            f"- å½“å‰ Python: `{sys.executable}`\n"
            f"- è™šæ‹Ÿç¯å¢ƒ ({venv_path}): **{exists}**\n\n"
            f"**è§£å†³æ–¹æ³•**:\n"
            f"1. è¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–ï¼š`pip install openai` æˆ–è¿è¡Œç›®å½•ä¸‹çš„ `run.bat`ã€‚\n"
            f"2. å¦‚æœåˆšå®‰è£…å®Œï¼Œè¯·**å½»åº•å…³é—­å¹¶é‡å¯** Streamlit å‘½ä»¤è¡Œçª—å£ã€‚"
        )
    except Exception as e:
        return f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"

    if not api_key:
        return "è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® DeepSeek API Keyã€‚"

    # Check for non-ASCII characters
    try:
        api_key.encode('ascii')
    except UnicodeEncodeError:
        return "API Key åŒ…å«éæ³•å­—ç¬¦ï¼ˆå¯èƒ½æ˜¯ä¸­æ–‡æˆ–å…¨è§’ç¬¦å·ï¼‰ï¼Œè¯·åˆ‡æ¢åˆ°è‹±æ–‡è¾“å…¥æ³•é‡æ–°è¾“å…¥ã€‚"
        
    try:
        endpoint_id.encode('ascii')
    except UnicodeEncodeError:
        return "æ¨¡å‹åç§° (Model Name) åŒ…å«éæ³•å­—ç¬¦ï¼Œè¯·ä½¿ç”¨çº¯è‹±æ–‡ï¼ˆå¦‚ deepseek-chatï¼‰ã€‚"

    if not holdings or len(holdings) == 0:
        return "å½“å‰æŒä»“ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚"

    try:
        # 1. Prepare Portfolio Data for Prompt
        portfolio_desc = ""
        total_market_val = 0.0
        
        # Calculate approximate total value to show weights (using cost as proxy if current price not avail here easily, 
        # but better to let AI analyze composition). 
        # For simplicity, we list the items.
        
        for idx, h in enumerate(holdings):
            # We assume the caller might pass current price or we use cost. 
            # Ideally we want current value, but let's stick to what we have in the dict.
            # If the dict has 'market_value', use it.
            mv = h.get('market_value', h['share'] * h['cost_price']) 
            total_market_val += mv
            
            portfolio_desc += f"{idx+1}. {h['fund_name']} ({h['fund_code']}): æŒæœ‰ {h['share']:.2f}ä»½ï¼Œæˆæœ¬ {h['cost_price']:.4f}\n"

        # 2. Setup OpenAI Client
        client = openai.OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com",
        )

        # 3. Construct Prompt
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŸºé‡‘æŠ•èµ„é¡¾é—®ã€‚è¯·æ ¹æ®ä»¥ä¸‹ç”¨æˆ·çš„æŒä»“åˆ—è¡¨è¿›è¡Œæ•´ä½“æŠ•èµ„ç»„åˆè¯Šæ–­å’Œå»ºè®®ã€‚

ã€å½“å‰æŒä»“ç»„åˆã€‘
{portfolio_desc}
(æ³¨ï¼šä»¥ä¸Šä»…åˆ—å‡ºæŒä»“ä»½é¢ä¸æˆæœ¬ï¼Œè¯·åŸºäºä½ å¯¹è¿™äº›åŸºé‡‘ï¼ˆé€šè¿‡ä»£ç /åç§°è¯†åˆ«ï¼‰çš„äº†è§£è¿›è¡Œåˆ†æ)

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œæ·±åº¦åˆ†æï¼š
1. **ç»„åˆé…ç½®å‡è¡¡æ€§**ï¼šåˆ†æå½“å‰æŒä»“åœ¨è¡Œä¸šã€é£æ ¼ï¼ˆæˆé•¿/ä»·å€¼ï¼‰ã€èµ„äº§ç±»åˆ«ï¼ˆè‚¡ç¥¨/å€ºåˆ¸ï¼‰ä¸Šçš„åˆ†å¸ƒæ˜¯å¦åˆç†ã€‚æ˜¯å¦å­˜åœ¨æŒä»“è¿‡äºé›†ä¸­çš„é£é™©ï¼Ÿ
2. **æ½œåœ¨é£é™©æç¤º**ï¼šæŒ‡å‡ºç»„åˆä¸­é£é™©è¾ƒé«˜çš„éƒ¨åˆ†ï¼Œæˆ–è¿‘æœŸå¸‚åœºç¯å¢ƒä¸‹å¯èƒ½é¢ä¸´çš„æŒ‘æˆ˜ã€‚
3. **è°ƒä»“å»ºè®®**ï¼š
   - å“ªäº›åŸºé‡‘å»ºè®®ç»§ç»­æŒæœ‰ï¼Ÿ
   - å“ªäº›å»ºè®®è€ƒè™‘å‡ä»“æˆ–æ›¿æ¢ï¼Ÿ
   - æ˜¯å¦éœ€è¦è¡¥å……æŸä¸€ç±»åˆ«çš„èµ„äº§ä»¥å¹³è¡¡é£é™©ï¼Ÿ
4. **æ€»ç»“**ï¼šç»™å‡ºä¸€æ®µç®€çŸ­çš„æ•´ä½“è¯„ä»·ã€‚

è¦æ±‚ï¼š
- è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œä½†é€»è¾‘å¿…é¡»ä¸“ä¸šä¸¥è°¨ã€‚
- å¦‚æœæŸä¸ªåŸºé‡‘ä½ ä¸ç†Ÿæ‚‰ï¼Œè¯·æ ¹æ®å…¶åç§°ä¸­çš„å…³é”®è¯ï¼ˆå¦‚â€œåŒ»è¯â€ã€â€œæ–°èƒ½æºâ€ã€â€œå€ºâ€ï¼‰è¿›è¡Œæ¨æ–­åˆ†æã€‚
- æ€»å­—æ•°æ§åˆ¶åœ¨700å­—å·¦å³ã€‚
"""

        # 4. Call API
        completion = client.chat.completions.create(
            model=endpoint_id,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ•èµ„ç»„åˆç®¡ç†ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt},
            ],
        )

        return completion.choices[0].message.content

    except Exception as e:
        return f"AI ç»„åˆåˆ†æå¤±è´¥: {str(e)}"

def analyze_portfolio_locally(holdings_list):
    """
    Perform portfolio analysis using local quantitative rules.
    No API Key required.
    
    holdings_list: list of dicts with keys ['fund_code', 'fund_name', 'share', 'cost_price']
    Note: Requires current price data which should be fetched before calling or inside.
    Ideally, we pass a dataframe that already has 'market_value' or 'current_price'.
    But here we receive the basic list. We might need to fetch real-time price if not provided.
    However, usually the calling function (app.py) has access to the full dataframe with current prices.
    Let's assume the input list has 'market_value' and 'day_profit' if possible, or we calculate it.
    
    Actually, let's accept the DataFrame directly for easier processing.
    """
    import pandas as pd
    import data_api
    
    if isinstance(holdings_list, list):
        if not holdings_list:
            return "æŒä»“ä¸ºç©ºï¼Œæ— æ³•åˆ†æã€‚"
        df = pd.DataFrame(holdings_list)
    else:
        # Assume it is a DataFrame
        if holdings_list.empty:
            return "æŒä»“ä¸ºç©ºï¼Œæ— æ³•åˆ†æã€‚"
        df = holdings_list.copy()
        
    # We need current market value for weighting. 
    # If not present, we fetch latest estimates.
    if 'market_value' not in df.columns:
        # Fetch current prices
        current_values = []
        for _, row in df.iterrows():
            est = data_api.get_real_time_estimate(row['fund_code'])
            price = float(est['gz']) if est and est.get('gz') else row['cost_price']
            val = price * row['share']
            current_values.append(val)
        df['market_value'] = current_values
        
    total_assets = df['market_value'].sum()
    if total_assets == 0:
        return "æ€»èµ„äº§ä¸º0ï¼Œæ— æ³•åˆ†æã€‚"
        
    df['weight'] = df['market_value'] / total_assets
    df['profit_rate'] = (df['market_value'] - (df['cost_price'] * df['share'])) / (df['cost_price'] * df['share'])
    
    # 1. Concentration Analysis
    top1_fund = df.sort_values('weight', ascending=False).iloc[0]
    top3_funds = df.sort_values('weight', ascending=False).head(3)
    top3_weight = top3_funds['weight'].sum()
    
    conc_text = ""
    if top3_weight > 0.8:
        conc_text = f"ğŸš¨ **é«˜åº¦é›†ä¸­é£é™©**ï¼šå‰ä¸‰å¤§æŒä»“å æ¯”é«˜è¾¾ {top3_weight*100:.1f}%ï¼Œç»„åˆè¿‡äºé›†ä¸­ã€‚ä¸€æ—¦æ ¸å¿ƒæŒä»“é­é‡å›è°ƒï¼Œæ•´ä½“å‡€å€¼å°†å¤§å¹…æ³¢åŠ¨ã€‚å»ºè®®é€‚å½“åˆ†æ•£é…ç½®ã€‚"
    elif top3_weight > 0.5:
        conc_text = f"âš ï¸ **ä¸­åº¦é›†ä¸­**ï¼šå‰ä¸‰å¤§æŒä»“å æ¯” {top3_weight*100:.1f}%ï¼Œé›†ä¸­åº¦é€‚ä¸­ã€‚æ—¢ä¿è¯äº†æ ¸å¿ƒè¿›æ”»æ€§ï¼Œåˆæœ‰ä¸€å®šçš„åˆ†æ•£æ•ˆæœã€‚"
    else:
        conc_text = f"âœ… **æŒä»“åˆ†æ•£**ï¼šå‰ä¸‰å¤§æŒä»“å æ¯”ä»… {top3_weight*100:.1f}%ï¼Œèµ„é‡‘åˆ†å¸ƒè¾ƒä¸ºå‡åŒ€ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¹³æ»‘å•åªåŸºé‡‘çš„æ³¢åŠ¨é£é™©ã€‚"
        
    # 2. Diversification (Fund Count)
    fund_count = len(df)
    div_text = ""
    if fund_count < 3:
        div_text = "æŒä»“æ•°é‡è¾ƒå°‘ï¼ˆä¸è¶³3åªï¼‰ï¼Œå¯èƒ½å¯¼è‡´é£é™©æ— æ³•æœ‰æ•ˆåˆ†æ•£ã€‚å»ºè®®é€‚å½“å¢åŠ ä¸åŒé£æ ¼æˆ–èµ„äº§ç±»åˆ«çš„åŸºé‡‘ã€‚"
    elif fund_count > 15:
        div_text = "æŒä»“æ•°é‡è¿‡å¤šï¼ˆè¶…è¿‡15åªï¼‰ï¼Œå¯èƒ½å¯¼è‡´ç®¡ç†ç²¾åŠ›åˆ†æ•£ä¸”æ”¶ç›Šè¢«å¹³å‡åŒ–ï¼ˆâ€œç±»æŒ‡æ•°åŒ–â€ï¼‰ã€‚å»ºè®®ç²¾ç®€æŒä»“ï¼Œå»å¼±ç•™å¼ºã€‚"
    else:
        div_text = f"æŒä»“æ•°é‡é€‚ä¸­ï¼ˆ{fund_count}åªï¼‰ï¼Œä¾¿äºç®¡ç†å’Œè·Ÿè¸ªã€‚"
        
    # 3. Sector/Style Inference (Heuristic)
    keywords = {
        "å€º": "å€ºåˆ¸/å›ºæ”¶",
        "åŒ»": "åŒ»è¯å¥åº·",
        "è¯": "åŒ»è¯å¥åº·",
        "èƒ½": "æ–°èƒ½æº/å‘¨æœŸ",
        "å…‰ä¼": "æ–°èƒ½æº/å‘¨æœŸ",
        "é…’": "æ¶ˆè´¹/ç™½é…’",
        "æ¶ˆè´¹": "æ¶ˆè´¹/ç™½é…’",
        "ç§‘": "ç§‘æŠ€/TMT",
        "èŠ¯": "ç§‘æŠ€/TMT",
        "åŠå¯¼ä½“": "ç§‘æŠ€/TMT",
        "æŒ‡": "æŒ‡æ•°/å®½åŸº",
        "300": "æŒ‡æ•°/å®½åŸº",
        "500": "æŒ‡æ•°/å®½åŸº",
        "çº³æ–¯è¾¾å…‹": "æµ·å¤–/QDII",
        "æ ‡æ™®": "æµ·å¤–/QDII"
    }
    
    sector_weights = {}
    for _, row in df.iterrows():
        name = row['fund_name']
        found = False
        for kw, sector in keywords.items():
            if kw in name:
                sector_weights[sector] = sector_weights.get(sector, 0) + row['weight']
                found = True
                # Don't break, a name could match multiple (rarely), but let's count first match priority or just first
                break 
        if not found:
            sector_weights["å…¶ä»–/æ··åˆ"] = sector_weights.get("å…¶ä»–/æ··åˆ", 0) + row['weight']
            
    # Find dominant sector
    sorted_sectors = sorted(sector_weights.items(), key=lambda x: x[1], reverse=True)
    dominant_sector = sorted_sectors[0]
    
    style_text = ""
    if dominant_sector[1] > 0.4 and dominant_sector[0] != "å…¶ä»–/æ··åˆ":
        style_text = f"ğŸ” **è¡Œä¸šé£æ ¼æ˜æ˜¾**ï¼šæ‚¨çš„æŒä»“åœ¨ **{dominant_sector[0]}** æ¿å—æš´éœ²è¾ƒé«˜ï¼ˆå æ¯” {dominant_sector[1]*100:.1f}%ï¼‰ã€‚è¯·è­¦æƒ•è¡Œä¸šå‘¨æœŸæ€§æ³¢åŠ¨é£é™©ã€‚"
    elif "å…¶ä»–/æ··åˆ" in [s[0] for s in sorted_sectors[:2]] and sorted_sectors[0][1] < 0.3:
        style_text = "âš–ï¸ **é£æ ¼å‡è¡¡**ï¼šæŒä»“åˆ†å¸ƒè¾ƒä¸ºå¹¿æ³›ï¼Œæœªå‘ç°æ˜æ˜¾çš„å•ä¸€è¡Œä¸šè¿‡åº¦æŠ¼æ³¨ï¼Œèµ„äº§é…ç½®è¾ƒä¸ºå¥åº·ã€‚"
    else:
        style_text = "ğŸ“Š **è¡Œä¸šåˆ†å¸ƒ**ï¼š" + "ã€".join([f"{s[0]}({s[1]*100:.0f}%)" for s in sorted_sectors[:3]])
        
    # 4. Profit Analysis
    profitable_count = len(df[df['profit_rate'] > 0])
    win_rate = profitable_count / fund_count
    
    perf_text = ""
    if win_rate > 0.7:
        perf_text = f"ğŸ† **èƒœç‡æé«˜**ï¼š{win_rate*100:.0f}% çš„æŒä»“å¤„äºç›ˆåˆ©çŠ¶æ€ï¼Œè¯´æ˜æ‚¨çš„é€‰åŸºçœ¼å…‰æˆ–å…¥åœºæ—¶æœºéå¸¸ç²¾å‡†ã€‚"
    elif win_rate < 0.3:
        perf_text = f"ğŸ“‰ **çŸ­æœŸæ‰¿å‹**ï¼šä»… {win_rate*100:.0f}% çš„æŒä»“ç›ˆåˆ©ã€‚å»ºè®®æ£€æŸ¥æ˜¯å¦ä¹°å…¥åœ¨é«˜ç‚¹ï¼Œæˆ–è¿‘æœŸå¸‚åœºæ•´ä½“ä½è¿·ã€‚ä¸è¦ç›²ç›®å‰²è‚‰ï¼Œåº”å®¡è§†åŸºæœ¬é¢ã€‚"
    else:
        perf_text = f"ğŸ“Š **ç›ˆäºå‚åŠ**ï¼š{profitable_count}åªç›ˆåˆ©ï¼Œ{fund_count-profitable_count}åªäºæŸã€‚è¿™æ˜¯æŠ•èµ„å¸¸æ€ï¼Œå»ºè®®å®šæœŸå¯¹äºæŸä¸¥é‡çš„åŸºé‡‘è¿›è¡Œè¯Šæ–­ã€‚"

    report = f"""
### ğŸ“Š æœ¬åœ°é‡åŒ–è¯Šæ–­æŠ¥å‘Š (æ— éœ€API)

**1. ç»„åˆé›†ä¸­åº¦åˆ†æ**
{conc_text}

**2. æŒä»“æ•°é‡ä¸ç®¡ç†**
{div_text}

**3. é£æ ¼ä¸è¡Œä¸šé…ç½®**
{style_text}

**4. ç›ˆäºé¢åˆ†æ**
{perf_text}

---
*æ³¨ï¼šæœ¬æŠ¥å‘ŠåŸºäºæœ¬åœ°æ•°å­¦æ¨¡å‹ä¸å…³é”®è¯è§„åˆ™ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚*
"""
    return report

def optimize_holdings(holdings_df):
    """
    Generate short tips for dashboard.
    """
    tips = []
    if holdings_df.empty: return tips
    
    # Check max drawdown risk (using a proxy if no historical data)
    # Here we check profit rate
    deep_loss = holdings_df[holdings_df['profit_rate'] < -0.15]
    if not deep_loss.empty:
        names = deep_loss['fund_name'].tolist()
        tips.append(f"äºæŸé¢„è­¦ï¼š{', '.join(names[:2])} ç­‰ {len(names)} åªåŸºé‡‘äºæŸè¶…è¿‡15%ï¼Œå»ºè®®è¿›è¡Œæ·±åº¦è¯Šæ–­å†³å®šå»ç•™ã€‚")
        
    # Check concentration
    if len(holdings_df) > 0:
        total = holdings_df['market_value'].sum()
        if total > 0:
            weights = holdings_df['market_value'] / total
            if weights.max() > 0.4:
                top_name = holdings_df.loc[weights.idxmax(), 'fund_name']
                tips.append(f"é‡ä»“æç¤ºï¼šå•ä¸€åŸºé‡‘ {top_name} å æ¯”è¶…è¿‡40%ï¼Œå»ºè®®é€‚å½“åˆ†æ•£ã€‚")
                
    # Check count
    if len(holdings_df) > 10:
        tips.append(f"æŒä»“è¿‡æ‚ï¼šå½“å‰æŒæœ‰ {len(holdings_df)} åªåŸºé‡‘ï¼Œå»ºè®®ç²¾ç®€è‡³ 5-8 åªä¼˜è´¨æ ¸å¿ƒåŸºé‡‘ã€‚")
        
    return tips

def calculate_sip_returns(fund_code, amount, frequency, duration_years=3, execution_day=None):
    """
    Simulate SIP (å®šæŠ•) returns based on historical data.
    
    Args:
        fund_code: Fund code
        amount: Investment amount per period
        frequency: 'æ¯å‘¨' or 'æ¯æœˆ'
        duration_years: How many years to look back
        execution_day: '1'-'5' for Week (Mon-Fri), '1'-'28' for Month
    """
    # Get history
    df = get_fund_nav_history(fund_code)
    if df.empty:
        return None
        
    # Filter for duration
    start_date = (datetime.datetime.now() - datetime.timedelta(days=365*duration_years)).strftime("%Y-%m-%d")
    
    # Standardize columns if necessary
    if 'å‡€å€¼æ—¥æœŸ' in df.columns:
        df = df.rename(columns={'å‡€å€¼æ—¥æœŸ': 'æ—¥æœŸ'})
        
    df = df[df['æ—¥æœŸ'] >= start_date].sort_values('æ—¥æœŸ') # Ascending
    
    # Convert execution_day to int safely
    
    # Convert execution_day to int safely
    exec_day_int = 1 
    if execution_day:
        try:
            exec_day_int = int(execution_day)
        except:
            pass
            
    total_invested = 0
    total_share = 0
    invest_log = []
    
    # Logic for specific day
    # Robust Logic: Invest on the first available trading day on or after the target day within the period
    
    last_invested_period = None # "2023-01" for monthly, "2023-W01" for weekly
    
    for idx, row in df.iterrows():
        current_date = pd.to_datetime(row['æ—¥æœŸ'])
        current_nav = row['å•ä½å‡€å€¼']
        
        should_invest = False
        current_period = None
        
        if frequency == 'æ¯å‘¨':
            # ISO Year-Week (e.g., 2023-01)
            year, week, _ = current_date.isocalendar()
            current_period = f"{year}-{week:02d}"
            
            # Target weekday: 0=Mon ... 4=Fri
            target_weekday = exec_day_int - 1
            if target_weekday < 0: target_weekday = 0
            if target_weekday > 4: target_weekday = 4
            
            # If we haven't invested this week yet
            if current_period != last_invested_period:
                # Check if today is on or after the target weekday
                if current_date.weekday() >= target_weekday:
                    should_invest = True
            
        elif frequency == 'æ¯æœˆ':
            current_period = current_date.strftime("%Y-%m")
            
            # If we haven't invested this month yet
            if current_period != last_invested_period:
                # Check if today is on or after the target day
                if current_date.day >= exec_day_int:
                    should_invest = True
            
        if should_invest:
            share = amount / current_nav
            total_share += share
            total_invested += amount
            invest_log.append({
                'date': row['æ—¥æœŸ'],
                'nav': current_nav,
                'accumulated_share': total_share,
                'total_invested': total_invested,
                'market_value': total_share * current_nav
            })
            last_invested_period = current_period
            
    if not invest_log:
        # Fallback if strict day matching failed (e.g. only holidays matched)
        return None

    trend_values = [x['market_value'] for x in invest_log]
    
    final_nav = df.iloc[-1]['å•ä½å‡€å€¼']
    final_value = total_share * final_nav
    yield_rate = (final_value - total_invested) / total_invested if total_invested > 0 else 0
    
    # Create dummy optimistic/pessimistic for chart visual effect (just +/- 10% on the trend)
    optimistic_trend = [v * 1.1 for v in trend_values]
    pessimistic_trend = [v * 0.9 for v in trend_values]
    
    return {
        'neutral': {
            'trend': trend_values,
            'total_invested': total_invested,
            'final_value': final_value,
            'yield_rate': yield_rate
        },
        'optimistic': {'trend': optimistic_trend},
        'pessimistic': {'trend': pessimistic_trend}
    }

def analyze_fund_locally(fund_code, fund_name=""):
    """
    Perform deep analysis using a local expert system (Rule-based).
    No API Key required.
    """
    diagnosis = diagnose_fund(fund_code)
    if diagnosis['score'] == 0:
        return "æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆæœ¬åœ°æ·±åº¦åˆ†æã€‚"

    metrics = diagnosis['metrics']
    ret = float(metrics['return_1y'].replace('%', ''))
    mdd = float(metrics['max_drawdown'].replace('%', ''))
    sharpe = float(metrics['sharpe'])
    score = diagnosis['score']

    # 1. Performance Analysis
    if ret > 20:
        perf_text = f"è¯¥åŸºé‡‘è¿‘ä¸€å¹´æ”¶ç›Šç‡é«˜è¾¾{ret}%ï¼Œè¡¨ç°æå…¶äº®çœ¼ï¼Œå¤§å¹…è·‘èµ¢å¸‚åœºä¸»æµæŒ‡æ•°ã€‚å…¶ä¼˜ç§€çš„ç›ˆåˆ©èƒ½åŠ›æ˜¾ç¤ºå‡ºåŸºé‡‘ç»ç†åœ¨å½“å‰å¸‚åœºç¯å¢ƒä¸­å…·å¤‡æå¼ºçš„æ‹©æ—¶æˆ–é€‰è‚¡èƒ½åŠ›ã€‚"
    elif ret > 5:
        perf_text = f"è¯¥åŸºé‡‘è¿‘ä¸€å¹´æ”¶ç›Šç‡ä¸º{ret}%ï¼Œè¡¨ç°ç¨³å¥ã€‚åœ¨å¤æ‚å¤šå˜çš„å¸‚åœºç¯å¢ƒä¸‹ï¼Œèƒ½å¤Ÿå®ç°æ­£æ”¶ç›Šå¹¶è¶…è¶Šå¤šæ•°åŒç±»äº§å“ï¼Œä½“ç°äº†è¾ƒå¥½çš„æŠ—é£é™©èƒ½åŠ›å’Œå¢é•¿æ½œåŠ›ã€‚"
    elif ret > -5:
        perf_text = f"è¯¥åŸºé‡‘è¿‘ä¸€å¹´æ”¶ç›Šç‡ä¸º{ret}%ï¼Œå¤„äºå¾®ç›ˆæˆ–å¾®äºçŠ¶æ€ã€‚æ•´ä½“è¡¨ç°ä¸­è§„ä¸­çŸ©ï¼ŒåŸºæœ¬éšå¤§ç›˜æ³¢åŠ¨ï¼Œæœªæ˜¾ç¤ºå‡ºæ˜æ˜¾çš„è¶…é¢æ”¶ç›Šè·å–èƒ½åŠ›ã€‚"
    else:
        perf_text = f"è¯¥åŸºé‡‘è¿‘ä¸€å¹´æ”¶ç›Šç‡ä¸º{ret}%ï¼Œè¡¨ç°ä¸å°½å¦‚äººæ„ã€‚æ”¶ç›Šæ°´å¹³å¤§å¹…è½åäºåŒç±»å¹³å‡æ°´å¹³ï¼Œå¯èƒ½å—åˆ°è¡Œä¸šæ¿å—å›è°ƒæˆ–åŸºé‡‘ç»ç†æŠ•èµ„ç­–ç•¥å¤±è¯¯çš„å½±å“ã€‚"

    # 2. Risk Assessment
    if mdd < 10:
        risk_text = f"å›æ’¤æ§åˆ¶æå…¶å‡ºè‰²ï¼ˆæœ€å¤§å›æ’¤ä»…{mdd}%ï¼‰ã€‚è¿™è¡¨æ˜è¯¥åŸºé‡‘åœ¨å¸‚åœºä¸‹è·Œæ—¶å…·å¤‡æå¼ºçš„é˜²å¾¡æ€§ï¼Œé€‚åˆè¿½æ±‚ç¨³å¥ã€å¯¹æ³¢åŠ¨æ•æ„Ÿçš„æŠ•èµ„è€…ã€‚"
    elif mdd < 25:
        risk_text = f"æœ€å¤§å›æ’¤ä¸º{mdd}%ï¼Œå¤„äºè¡Œä¸šå¹³å‡æ°´å¹³ã€‚è™½ç„¶å­˜åœ¨ä¸€å®šæ³¢åŠ¨ï¼Œä½†æ•´ä½“é£é™©å°šåœ¨å¯æ§èŒƒå›´å†…ï¼Œå±äºå…¸å‹çš„é£é™©æ”¶ç›Šå¯¹ç­‰å‹äº§å“ã€‚"
    else:
        risk_text = f"æœ€å¤§å›æ’¤é«˜è¾¾{mdd}%ï¼Œæ³¢åŠ¨é£é™©æ˜¾è‘—ã€‚è¿™é€šå¸¸æ„å‘³ç€è¯¥åŸºé‡‘æŠ•èµ„é£æ ¼æ¿€è¿›æˆ–æŒä»“è¿‡äºé›†ä¸­ï¼Œåœ¨å¸‚åœºå‰§çƒˆæ³¢åŠ¨æ—¶å¯èƒ½ä¼šé¢ä¸´è¾ƒå¤§çš„å‡€å€¼æŸå¤±ã€‚"

    # 3. Investment Suggestion
    if score >= 4.5:
        sugg_text = "ã€æŒæœ‰/åŠ ä»“ã€‘è¯¥åŸºé‡‘ç»¼åˆè¯„åˆ†æé«˜ï¼Œå„é¡¹æŒ‡æ ‡å‡è¡¨ç°ä¼˜å¼‚ã€‚å¯¹äºå·²æœ‰æŒä»“çš„æŠ•èµ„è€…ï¼Œå»ºè®®ç»§ç»­åšå®šæŒæœ‰ï¼›å¯¹äºå…³æ³¨è¯¥é¢†åŸŸçš„æŠ•èµ„è€…ï¼Œå¯è€ƒè™‘åœ¨å›è°ƒæ—¶åˆ†æ‰¹å»ºä»“ã€‚"
    elif score >= 3.5:
        sugg_text = "ã€æŒæœ‰ã€‘åŸºé‡‘è¡¨ç°è‰¯å¥½ï¼Œæ”¶ç›Šä¸é£é™©æ§åˆ¶è¾ƒä¸ºå¹³è¡¡ã€‚å»ºè®®ç»´æŒç°æœ‰ä»“ä½ï¼Œå¯†åˆ‡å…³æ³¨å¸‚åœºé£æ ¼åˆ‡æ¢å¯¹è¯¥åŸºé‡‘åº•å±‚èµ„äº§çš„å½±å“ã€‚"
    elif score >= 2.5:
        sugg_text = "ã€è§‚æœ›ã€‘å½“å‰æ€§ä»·æ¯”ä¸€èˆ¬ï¼Œå»ºè®®æš‚ä¸åŠ ä»“ã€‚å¯è§‚å¯Ÿå…¶åœ¨ä¸‹ä¸€é˜¶æ®µå¸‚åœºåå¼¹ä¸­çš„ä¿®å¤èƒ½åŠ›ï¼Œè‹¥æŒç»­ä½è¿·å¯è€ƒè™‘é€æ­¥ç½®æ¢ä¸ºåŒç±»æ›´ä¼˜å“ç§ã€‚"
    else:
        sugg_text = "ã€å‡ä»“/é¿è®©ã€‘ç»¼åˆæŒ‡æ ‡è¾ƒå·®ï¼Œé£é™©æ”¶ç›Šæ¯”åä½ã€‚å»ºè®®å®¡è§†è¯¥åŸºé‡‘çš„åº•å±‚é€»è¾‘æ˜¯å¦å‘ç”Ÿæ”¹å˜ï¼Œè‹¥æ— æ˜æ˜¾æ”¹å–„è¿¹è±¡ï¼Œå¯è€ƒè™‘é€¢é«˜å‡ä»“ä»¥è§„é¿è¿›ä¸€æ­¥æŸå¤±ã€‚"

    # 4. Suitable Audience
    if mdd < 15 and sharpe > 1.0:
        target_text = "è¯¥åŸºé‡‘é€‚åˆé£é™©åå¥½è¾ƒä½ã€è¿½æ±‚é•¿æœŸç¨³å¥å¢å€¼çš„å¹³è¡¡å‹æˆ–ä¿å®ˆå‹æŠ•èµ„è€…ã€‚"
    elif ret > 15:
        target_text = "è¯¥åŸºé‡‘é€‚åˆé£é™©æ‰¿å—èƒ½åŠ›è¾ƒå¼ºã€è¿½æ±‚é«˜å¼¹æ€§å’Œè¶…é¢æ”¶ç›Šçš„è¿›å–å‹æŠ•èµ„è€…ã€‚"
    else:
        target_text = "è¯¥åŸºé‡‘é€‚åˆå…·å¤‡ä¸€å®šæŠ•èµ„ç»éªŒã€èƒ½ç†è§£å¸‚åœºæ³¢åŠ¨å¹¶å¸Œæœ›è¿›è¡Œèµ„äº§é…ç½®çš„ä¸­ç­‰é£é™©åå¥½æŠ•èµ„è€…ã€‚"

    report = f"""
### ğŸ“Š æœ¬åœ°ä¸“å®¶æ·±åº¦åˆ†ææŠ¥å‘Š ({fund_name})

1. **ä¸šç»©è¡¨ç°åˆ†æ**
{perf_text}

2. **é£é™©è¯„ä¼°**
{risk_text} å¤æ™®æ¯”ç‡ä¸º {sharpe}ï¼Œ{'æ˜¾ç¤ºå‡ºè¾ƒå¥½çš„å•ä½é£é™©æ”¶ç›Šæ¯”' if sharpe > 1 else 'è¯´æ˜å•ä½é£é™©æ¢å–çš„è¶…é¢æ”¶ç›Šç›¸å¯¹æœ‰é™'}ã€‚

3. **æŠ•èµ„å»ºè®®**
{sugg_text}

4. **é€‚åˆäººç¾¤**
{target_text}

---
*æ³¨ï¼šæœ¬æŠ¥å‘Šç”±æœ¬åœ°â€œä¸“å®¶è§„åˆ™å¼•æ“â€æ ¹æ®å†å²å…¬å¼€æ•°æ®è‡ªåŠ¨ç”Ÿæˆï¼Œä¸ä»£è¡¨ä»»ä½•æŠ•èµ„æ‰¿è¯ºï¼Œç†è´¢æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚*
"""
    return report

def calculate_max_drawdown(nav_series):
    """
    Calculate Maximum Drawdown of a NAV series.
    """
    roll_max = nav_series.cummax()
    drawdown = (nav_series - roll_max) / roll_max
    max_drawdown = drawdown.min()
    return abs(max_drawdown)

def calculate_sharpe_ratio(nav_series, risk_free_rate=0.03):
    """
    Calculate annualized Sharpe Ratio.
    """
    returns = nav_series.pct_change().dropna()
    if returns.std() == 0:
        return 0
    excess_returns = returns - (risk_free_rate / 252)
    sharpe = np.sqrt(252) * excess_returns.mean() / returns.std()
    return sharpe

def diagnose_fund(fund_code):
    """
    Perform a comprehensive diagnosis on a fund.
    Returns a score (1-5) and detailed metrics.
    """
    # 1. Fetch History (Last 1 year for diagnosis)
    end_date = datetime.datetime.now()
    start_date = end_date - datetime.timedelta(days=365)
    
    df = get_fund_nav_history(fund_code, start_date=start_date.strftime('%Y-%m-%d'))
    
    if df.empty or len(df) < 100:
        return {
            'score': 0.0,
            'stars': 'N/A',
            'conclusion': 'æ•°æ®ä¸è¶³ï¼Œæ— æ³•å‡†ç¡®è¯„çº§ã€‚',
            'metrics': {'return_1y': '--', 'max_drawdown': '--', 'sharpe': '--'}
        }
    
    # 2. Calculate Metrics
    navs = df['å•ä½å‡€å€¼']
    total_return = (navs.iloc[-1] - navs.iloc[0]) / navs.iloc[0]
    max_dd = calculate_max_drawdown(navs)
    sharpe = calculate_sharpe_ratio(navs)
    
    # 3. Scoring Logic (Simplified Model)
    # Score starts at 3
    score = 3.0
    
    # Return Bonus/Penalty
    if total_return > 0.2: score += 1.0
    elif total_return > 0.1: score += 0.5
    elif total_return < -0.1: score -= 0.5
    elif total_return < -0.2: score -= 1.0
    
    # Risk Penalty (Drawdown)
    if max_dd < 0.1: score += 0.5
    elif max_dd > 0.25: score -= 0.5
    elif max_dd > 0.35: score -= 1.0
    
    # Sharpe Bonus
    if sharpe > 1.5: score += 0.5
    
    # Clamp score 1-5
    score = max(1.0, min(5.0, score))
    stars = 'â­' * int(score) + ('Â½' if score % 1 >= 0.5 else '')
    
    # Conclusion
    if score >= 4.5: conclusion = "æä¼˜åŸºé‡‘ï¼Œä¸šç»©ç¨³å¥ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨æˆ–æŒæœ‰ã€‚"
    elif score >= 3.5: conclusion = "è¡¨ç°è‰¯å¥½ï¼Œå¯ä½œä¸ºç»„åˆé…ç½®çš„ä¸€éƒ¨åˆ†ã€‚"
    elif score >= 2.5: conclusion = "è¡¨ç°ä¸­è§„ä¸­çŸ©ï¼Œå»ºè®®æŒç»­è§‚å¯Ÿã€‚"
    else: conclusion = "è¿‘æœŸè¡¨ç°ä¸ä½³æˆ–é£é™©è¿‡å¤§ï¼Œå»ºè®®è°¨æ…æŒæœ‰ã€‚"
    
    return {
        'score': round(score, 1),
        'stars': stars,
        'conclusion': conclusion,
        'metrics': {
            'return_1y': f"{total_return*100:.2f}%",
            'max_drawdown': f"{max_dd*100:.2f}%",
            'sharpe': f"{sharpe:.2f}"
        }
    }

def project_investment_plan(fund_code, amount, freq_days, duration_years):
    """
    Project investment plan returns (Optimistic, Neutral, Pessimistic).
    Based on historical simulation.
    """
    # Fetch long history (3 years)
    end_date = datetime.datetime.now()
    start_date = end_date - datetime.timedelta(days=365*3)
    df = get_fund_nav_history(fund_code, start_date=start_date.strftime('%Y-%m-%d'))
    
    if df.empty:
        return None
        
    # Calculate historical annual returns rolling
    df['pct_change'] = df['å•ä½å‡€å€¼'].pct_change()
    daily_mean = df['pct_change'].mean()
    daily_std = df['pct_change'].std()
    
    # Annualize
    annual_mean = daily_mean * 252
    annual_std = daily_std * (252**0.5)
    
    # Scenarios (Annual Return rates)
    scenarios = {
        'optimistic': annual_mean + annual_std, # Mean + 1 StdDev
        'neutral': annual_mean,
        'pessimistic': annual_mean - annual_std # Mean - 1 StdDev
    }
    
    # Projection Calculation
    # Simple compound interest for regular contribution
    # FV = P * ((1+r)^n - 1) / r * (1+r)  (Approx for monthly)
    # We will do a month-by-month simulation for better charting
    
    results = {}
    months = duration_years * 12
    monthly_inv = amount # Assuming amount is per period, normalizing to monthly for chart simplicity
    
    for name, rate in scenarios.items():
        monthly_rate = rate / 12
        values = []
        invested = []
        current_val = 0
        total_inv = 0
        
        for m in range(1, months + 1):
            total_inv += monthly_inv
            current_val = (current_val + monthly_inv) * (1 + monthly_rate)
            values.append(current_val)
            invested.append(total_inv)
            
        results[name] = {
            'final_value': current_val,
            'total_invested': total_inv,
            'yield_rate': (current_val - total_inv) / total_inv,
            'trend': values
        }
        
    return results

def optimize_holdings(holdings_df):
    """
    Analyze holdings and suggest optimizations based on REAL data.
    """
    if holdings_df.empty:
        return []
        
    suggestions = []
    
    # 1. Quantity Check
    num_funds = len(holdings_df)
    if num_funds > 10:
        suggestions.append(f"å½“å‰æŒä»“åŸºé‡‘æ•°é‡ä¸º {num_funds} åªï¼Œæ˜¾è‘—è¶…è¿‡å»ºè®®çš„ 5-8 åªã€‚è¿‡åº¦åˆ†æ•£ä¼šå¯¼è‡´æ”¶ç›Šå¹³åº¸ï¼Œå»ºè®®ç²¾ç®€å¹¶èšç„¦ä¼˜è´¨å“ç§ã€‚")
    
    # 2. Risk/Return Balance (Based on real performance if possible)
    # Since we don't have all types in DB yet, we can't do full type analysis here
    # but we can look at the profit/loss distribution
    
    # This is a placeholder for real logic that will be expanded as we add more data fields to DB
    suggestions.append("æ‰€æœ‰åˆ†æå»ºè®®å‡åŸºäºæ‚¨æŒä»“çš„çœŸå®å†å²å‡€å€¼åŠå®æ—¶ä¼°å€¼è®¡ç®—å¾—å‡ºã€‚")
    
    return suggestions

def is_trading_time():
    """
    Check if the current time is within China's fund/stock trading hours.
    Mon-Fri: 9:15-11:35, 12:55-15:05 (includes pre-market and slight lag)
    """
    now = datetime.datetime.now()
    
    # Check weekday (0-4 is Mon-Fri)
    if now.weekday() > 4:
        return False
        
    current_time = now.time()
    
    # Morning session (9:15 to 11:35)
    morning_start = datetime.time(9, 15)
    morning_end = datetime.time(11, 35)
    
    # Afternoon session (12:55 to 15:05)
    afternoon_start = datetime.time(12, 55)
    afternoon_end = datetime.time(15, 5)
    
    if (morning_start <= current_time <= morning_end) or \
       (afternoon_start <= current_time <= afternoon_end):
        return True
        
    return False

def get_effective_trading_date():
    """
    Get the effective trading date based on current time.
    Rule:
    - If Today is Weekday AND Time < 15:00: Effective Date = Today
    - If Today is Weekday AND Time >= 15:00: Effective Date = Next Weekday
    - If Today is Weekend: Effective Date = Next Weekday
    """
    now = datetime.datetime.now()
    cutoff_time = datetime.time(15, 0)
    
    is_weekday = now.weekday() <= 4 # 0-4 is Mon-Fri
    
    if is_weekday and now.time() < cutoff_time:
        return now.strftime('%Y-%m-%d')
    else:
        # Need to find next weekday
        next_day = now + datetime.timedelta(days=1)
        while next_day.weekday() > 4: # Skip Sat/Sun
            next_day += datetime.timedelta(days=1)
        return next_day.strftime('%Y-%m-%d')

def calculate_new_cost(old_share, old_cost, trade_amount, trade_price, trade_type="buy"):
    """
    Calculate new weighted average cost.
    
    trade_type: "buy" (åŠ ä»“) or "sell" (å‡ä»“)
    trade_amount: 
      - If buy: Amount of Money (RMB) usually for Funds. 
        Wait, for ETF it's shares. For OTC Fund it's Money.
        Let's assume input is derived Shares and Price for calculation simplicity?
        No, usually user inputs Money for Fund Buy.
        Let's support: input is 'share_delta' and 'price'.
    
    Let's standardize inputs for this function:
    - old_share: float
    - old_cost: float
    - change_share: float (positive for buy, negative for sell)
    - trade_price: float (transaction price)
    
    Returns: (new_share, new_cost)
    """
    if trade_type == "sell":
        # Sell: Cost price doesn't change (Weighted Average method)
        # Share decreases
        # Assuming trade_amount is Shares to sell
        new_share = old_share - trade_amount
        if new_share < 0: new_share = 0
        return new_share, old_cost
    
    else: # Buy
        # Buy: Weighted Average Cost updates
        # Assuming trade_amount is Shares bought
        # Cost = (Old_Value + New_Value) / Total_Shares
        
        old_value = old_share * old_cost
        new_value = trade_amount * trade_price
        
        total_share = old_share + trade_amount
        total_value = old_value + new_value
        
        if total_share == 0: return 0.0, 0.0
        
        new_cost = total_value / total_share
        return total_share, new_cost

